#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
5Unsupervised_Stroke_Detection.py

This script implements an unsupervised change‐point detection method to detect
tennis stroke boundaries from normalized pose estimation CSV data.

It performs the following steps:
1. Load the normalized CSV data (generated by 3Full_Video_Normalization.py).
2. Compute a composite velocity signal from selected key landmarks.
3. Compute a composite acceleration signal (as the derivative of velocity).
4. Smooth the acceleration signal with a Savitzky–Golay filter.
5. Run a change‑point detection algorithm (using ruptures’ PELT) on the smoothed signal.
6. Convert the detected change points into stroke segmentation boundaries.
7. Use FFmpeg to clip the original video into stroke segments.

Adjust the parameters as needed.
"""

import os
import csv
import math
import numpy as np
import cv2
import ffmpeg
import ruptures as rpt  # Unsupervised change-point detection

from scipy.signal import savgol_filter

#############################################
# CONFIGURATION SETTINGS
#############################################
# Path settings (adjust as needed)
NORMALIZED_CSV = "Test_media/test_videos/video_1_data.csv"  # Normalized pose CSV
ORIGINAL_VIDEO = "Test_media/test_videos/video_1.mp4"                 # Original video file
OUTPUT_STROKE_FOLDER = "tennis_clips/strokes_unsupervised"         # Folder to save stroke clips
os.makedirs(OUTPUT_STROKE_FOLDER, exist_ok=True)

# Video parameters
FPS = 30  # Frames per second of the video

# Landmarks used to compute the composite metric (shoulders, elbows, wrists, hips)
SELECTED_LANDMARKS = [11, 12, 13, 14, 15, 16, 23, 24]

# Smoothing parameters for the acceleration signal
SMOOTH_WINDOW = 61      # Must be odd; adjust as needed
SMOOTH_POLY_ORDER = 2

# Parameters for change-point detection using ruptures
# Here, we choose the PELT method with an 'rbf' cost model.
# The "pen" parameter controls the sensitivity (higher means fewer change points).
RUPTURES_PENALTY = 10.0  # Adjust this penalty to change sensitivity

# Minimum stroke duration in seconds
MIN_STROKE_DURATION_SEC = 3

#############################################
# FUNCTIONS
#############################################
def load_normalized_csv(csv_path):
    """
    Load the normalized CSV data.
    Assumes the CSV columns: frame_index, then 33*4 columns of raw pose data.
    Returns a list of rows (each row is a list of floats).
    """
    data = []
    with open(csv_path, "r") as f:
        reader = csv.reader(f)
        header = next(reader)  # skip header
        for row in reader:
            # Convert only the first (1+33*4=133) columns to float
            data.append([float(x) for x in row[:133]])
    return data

def extract_landmark_xy(frame_row, lm_index):
    """
    Given a frame row (list of floats) from the CSV,
    extract normalized x and y for landmark `lm_index`.
    The CSV columns: frame_index, lm_0_x, lm_0_y, lm_0_z, lm_0_vis, lm_1_x, ...
    So for landmark i, x is at index 1 + i*4 and y is at index 1 + i*4 + 1.
    """
    base = 1 + lm_index * 4
    x = frame_row[base]
    y = frame_row[base + 1]
    return x, y

def compute_composite_velocity(data):
    """
    Compute a composite velocity signal for each frame (except the first) based on the selected landmarks.
    For each frame, compute the Euclidean distance (in 2D) for each selected landmark from the previous frame,
    and then take the average.
    Returns a NumPy array of velocity values.
    """
    velocities = []
    for i in range(1, len(data)):
        diffs = []
        for lm in SELECTED_LANDMARKS:
            x1, y1 = extract_landmark_xy(data[i-1], lm)
            x2, y2 = extract_landmark_xy(data[i], lm)
            diff = math.sqrt((x2 - x1)**2 + (y2 - y1)**2)
            diffs.append(diff)
        velocities.append(np.mean(diffs))
    return np.array(velocities)

def compute_composite_acceleration(velocities, fps):
    """
    Compute composite acceleration as the numerical derivative of the velocity signal,
    multiplied by fps to scale per second.
    Returns a NumPy array of acceleration values.
    """
    acceleration = np.diff(velocities) * fps
    return acceleration

def smooth_signal(signal, window, poly_order):
    """
    Apply Savitzky–Golay filter to smooth the signal.
    """
    if len(signal) < window:
        # Adjust window if signal is too short
        window = len(signal) if len(signal) % 2 == 1 else len(signal) - 1
    return savgol_filter(signal, window_length=window, polyorder=poly_order)

def detect_change_points(signal, penalty):
    """
    Use the ruptures PELT algorithm with an 'rbf' cost to detect change points in the signal.
    Returns an array of indices in the signal where change points occur.
    """
    # Create a PELT change point detection object with the 'rbf' cost model
    algo = rpt.Pelt(model="rbf").fit(signal)
    change_points = algo.predict(pen=penalty)
    # The last change point is usually the end of the signal; remove it if desired
    if change_points and change_points[-1] == len(signal):
        change_points = change_points[:-1]
    return np.array(change_points)

def clip_video(video_path, stroke_boundaries, fps, min_duration_sec, margin_sec=0):
    """
    Given the original video and a list of stroke boundary frame indices,
    compute stroke segments and clip the video using ffmpeg.
    Stroke segments are defined as between the midpoints of consecutive boundaries.
    Only segments longer than min_duration_sec are saved.
    """
    if len(stroke_boundaries) < 2:
        print("Not enough boundaries detected to clip strokes.")
        return

    # Convert frame indices to seconds
    times = [idx / fps for idx in stroke_boundaries]
    # Compute midpoints between consecutive boundaries
    stroke_cut_times = [(times[i] + times[i+1]) / 2 for i in range(len(times)-1)]
    
    # Define stroke segments as [start, end] pairs (adding optional margin)
    stroke_segments = []
    for i in range(len(stroke_cut_times)-1):
        t_start = max(0, stroke_cut_times[i] - margin_sec)
        t_end = stroke_cut_times[i+1] + margin_sec
        duration = t_end - t_start
        if duration < min_duration_sec:
            print(f"Skipping stroke segment {i+1} (duration {duration:.2f}s too short)")
            continue
        stroke_segments.append((t_start, t_end))
    
    # Clip each stroke segment using ffmpeg
    for i, (t_start, t_end) in enumerate(stroke_segments):
        output_clip = os.path.join(OUTPUT_STROKE_FOLDER, f"stroke_{i+1}.mp4")
        print(f"Clipping stroke {i+1}: start={t_start:.2f}s, end={t_end:.2f}s, duration={t_end - t_start:.2f}s")
        try:
            (
                ffmpeg
                .input(video_path, ss=t_start, to=t_end)
                .output(output_clip, codec="copy", loglevel="error", y=None)
                .run()
            )
        except Exception as e:
            print(f"Error clipping stroke {i+1}: {e}")
    print("Stroke clipping complete.")

#############################################
# MAIN EXECUTION
#############################################
def main():
    # Step 1: Load normalized CSV data
    print("Loading normalized CSV data...")
    data = load_normalized_csv(NORMALIZED_CSV)
    if not data:
        print("No data loaded from CSV!")
        return

    # Step 2: Compute composite velocity signal
    print("Computing composite velocity...")
    comp_velocity = compute_composite_velocity(data)

    # Step 3: Compute composite acceleration signal
    print("Computing composite acceleration...")
    comp_acceleration = compute_composite_acceleration(comp_velocity, FPS)

    # Step 4: Smooth the acceleration signal
    print("Smoothing acceleration signal...")
    smooth_accel = smooth_signal(comp_acceleration, SMOOTH_WINDOW, SMOOTH_POLY_ORDER)

    # Step 5: Detect change points (unsupervised stroke boundaries)
    print("Detecting change points using PELT...")
    change_points = detect_change_points(smooth_accel, RUPTURES_PENALTY)
    # Since the acceleration array has length (num_frames - 2), map back to original frame indices
    stroke_boundaries = (change_points + 1).tolist()  # add offset if needed
    print(f"Detected {len(stroke_boundaries)} stroke boundaries at frames: {stroke_boundaries}")

    # Step 6: Clip the video using the detected stroke boundaries
    print("Clipping strokes from video...")
    clip_video(ORIGINAL_VIDEO, stroke_boundaries, FPS, MIN_STROKE_DURATION_SEC, margin_sec=0)

if __name__ == '__main__':
    main()
